## Информация

База заполенна на 700MB


## Факты

Посмотрел код HttpSession, там при вызове обычного write каждый буфер оборачивается в Item.

Также, если сокет на данный момент заполнен, то все эти айтемы просто выстраиваются в связанный список,
таким образом, если сокет зависнет надолго, то в худшем случае мы выгрузим все наши данные.

Мне захотелось уйти от этой проблемы, поэтому реализовал свои Items для очереди.

При этом проблема с аллокацией нового айтема на каждый элемент в этом коде не решена.

Также мне захотелось учесть тот факт, что MemorySegment'ы могут не влезать в память, поддержку чего добавить можно,
при том не так уж и сложно, несмотря на то, что на данный момент слишком большие данные мы принять все равно не в силах

## Профилирование

Запустил один запрос на все данные и начал профилирование.
Сокет работает на 1 клиента, поэтому всегда свободен, и описанной ранее проблемы не возникает.
Что демонстрируют [локи](html%2Fstage6%2Fsolo_lock.html) (они пусты)

Как мы видим основное [время работы](html%2Fstage6%2Fsolo_cpu.html) занимает запись в сокет

В плане [аллокаций](html%2Fstage6%2Fsolo_alloc.html) всплывает проблема с аллокацией нового айтема для каждой
уникальной записи в нашем дао. В следствие, чего на аллокацию промежуточного буфера уходит основное время

При этом эту проблему можно достаточно просто решить, обычным переиспользованием одного элемента очереди,
т.к. считывание у нас происходит последовательно.

## Оптимизация

В коммите `643f950eb59595596eb1c237e5413084dd37dd75` использовал один чанк.

Как видно по [аллокациям](html%2Fstage6%2Foptimize_alloc.html) действительно стало лучше.
 
Теперь у нас нет постоянной аллокации буфера, что значительно снизило нагрузку.
Также можно переписать метод перевода числа в hex байты,
но опять же нужно учитывать заполненность буфера сокета (а мне лень)
